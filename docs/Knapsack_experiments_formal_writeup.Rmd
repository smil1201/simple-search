---
title: 'Knapsack experiment Full Report: Team Sleepless'
author: "Sam Miller, Richard Stangl, and Elsa Browning"
date: "November 7, 2016"
output: pdf_document
---

# Introduction

Our group chose to head in the direction of generational algorithms. We basically made an advanced version of hill-climber that works on an entire population instead of on individuals. Our method was to create a population of random instances and then mutate that generation. We then combined the mutated and original populations, sorted them, and took the better half of the individuals. We then repeat this process on each successive population until we find the ideal solution or until we reach the maximum number of tries.


# Experimental setup

We initially started with a `max-tries` value of 1000 for the default problem instances given:

* `knapPI_11_20_1000_4`
* `knapPI_13_20_1000_4` 
* `knapPI_16_20_1000_4`
* `knapPI_11_200_1000_4`
* `knapPI_13_200_1000_4`
* `knapPI_16_200_1000_4`

but as we progressed, we switched to focusing on instances of the type knapsackPI_16 variety. We utilized five of the twenty item instances and five of the thousand item instances:

* `knapPI_16_20_1000_1`
* `knapPI_16_20_1000_2`
* `knapPI_16_20_1000_3`
* `knapPI_16_20_1000_4`
* `knapPI_16_20_1000_5`

* `knapPI_16_1000_1000_1`
* `knapPI_16_1000_1000_2`
* `knapPI_16_1000_1000_3`
* `knapPI_16_1000_1000_4`
* `knapPI_16_1000_1000_5`


We also had a few runs that had a `max-tries` value of 10000.

# Results

## A comparison of our searcher to basic hill_climber


Here we plot the results of 1000 runs with 10000 `max-tries` on five of the 20 item problems.

```{r, echo=FALSE}
data_evo_1000_runs <- read.csv("../data/data_1000_runs_10000_tries_knap1620_evo_lexi.txt", sep="")
data_hill_1000_runs <- read.csv("../data/data_1000_runs_10000_tries_knap1620_hill_lexi.txt", sep="")

twenty_item <- rbind2(data_evo_1000_runs, data_hill_1000_runs)


plot(twenty_item$Score ~ twenty_item$Search_method, 
     main="Knapsack 16: Twenty-Item Problems", 
     xlab="Searcher", ylab="Score")

```


It is difficult to see any difference between the two, as they have similar performance.

Here is a summary, ours is only marginally better.

Hill Climber:
```{r, echo=FALSE, comment=""}
summary(data_hill_1000_runs$Score)
```


Evolutionary Algorithm:
```{r, echo=FALSE, comment=""}
summary(data_evo_1000_runs$Score)
```



Let's look at the more complex problems.



Here we plot the results of 50 runs with 10000 `max-tries` on five of the 1000 item problems
```{r, echo=FALSE}
data_evo_50_runs <- read.csv("../data/data_50_runs_10000_tries_knap16_evo_lexi.txt", sep="")
data_hill_50_runs <- read.csv("../data/data_50_runs_10000_tries_knap16_hill_lexi.txt", sep="")


thousand_item <- rbind2(data_evo_50_runs, data_hill_50_runs)

plot(thousand_item$Score ~ thousand_item$Search_method,
     main = "Knapsack problem 16: Thousand-Item Problems",
     xlab="Searcher", ylab="Score")

```

Here it is easier to see that our algorithm is performing better.
```{r, echo=FALSE, comment=""}
summary(data_hill_50_runs$Score)

summary(data_evo_50_runs$Score)
```

Let's test for statistical significance.

```{r, echo=FALSE, comment=""}
pairwise.wilcox.test(thousand_item$Score, thousand_item$Search_method)
```

Our p-value is <0.05 so we can conclude there is a difference in performance of some statistical significance.




Here is a comparison of score for each search method for the 1000 runs of the twenty item instances:
```{r warning=FALSE, echo=FALSE}
library("ggplot2")

ggplot(twenty_item, 
       aes(x=factor(Search_method), y=Score, group=Search_method)) + 
  geom_boxplot() + facet_grid(. ~ Problem)
```


Here is a comparison of score for each search method for the 1000 runs of the twenty item instances:
```{r warning=FALSE, echo=FALSE}
ggplot(thousand_item, 
       aes(x=factor(Search_method), y=Score, group=Search_method)) + 
  geom_boxplot() + facet_grid(. ~ Problem)
```






## How do things change by problem? Max evals?

As shown in the previous section, it is easier to see the improved performance in our searcher when you are operating on more complex problems that contain more items.

# Conclusions

While our algorithm does run slower than basic hill climber, it is able to find better solutions for each run. 


------









#Generational Algorithm

Our group chose to head in the direction of generational algorithms. We basically made an advanced version of hill-climber that works on an entire population instead of on individuals. Our method was to create a population of random instances and then mutate that generation. We then combined the mutated and original populations, sorted them, and took the better half of the individuals. We then repeat this process on each successive population until we find the ideal solution or until we reach the maximum number of tries.

```{r, echo=FALSE}
data_5_runs_evo_lexi <- read.csv("../data/data_5_runs_1000_tries_evo_alg_lexi.txt", sep="")

data_5_runs_evo_lexi$Non_negative_score = ifelse(data_5_runs_evo_lexi$Score<0, 0, data_5_runs_evo_lexi$Score)

plot(data_5_runs_evo_lexi$Non_negative_score ~ data_5_runs_evo_lexi$Search_method,
     main="Evolutionary Algorithm vs Hill Climber", xlab="Searcher", ylab="Score")
```

They look pretty similar here, both seem to reach a local maximum every time in the knapsack problems 11 and 13. However, in the knapsack problem 16, we out perform hill climber. So we chose to plot a couple of different problem instances from 16 to emphasize this difference.

```{r, echo=FALSE}
data_5_runs_evo_16 <- read.csv("../data/data_20_runs_knapPI_16_200_evo_alg_lexi.txt", sep="")

data_5_runs_evo_16$Non_negative_score = ifelse(data_5_runs_evo_16$Score<0, 0, data_5_runs_evo_16$Score)

plot(data_5_runs_evo_16$Non_negative_score ~data_5_runs_evo_16$Search_method,
     main="Knapsack Problem 16", xlab="Searcher", ylab="Score")
```


Now that we are focusing only on problem 16, the strengths of our algorithm our more apparent in that we outperform hill climber in every instance that we tested. We are reasonably confident that this is because we start with more hill climbers in different starting positions, giving us a better chance of finding the absolute maximum.





------------------------


